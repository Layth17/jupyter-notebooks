{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "556ca163-8f56-4072-9d35-9c55e21e1099",
   "metadata": {},
   "source": [
    "# Lab: Multilayer Perceptron (HW7-8) -- Layth Aljorani"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066b8823-69bf-498b-811d-ce013135601b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 0. Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3424db1-b636-43e8-b0c2-6c4306a4e1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 23:52:09.652914: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-09 23:52:10.304472: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-09 23:52:10.304500: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-09 23:52:10.307517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-09 23:52:10.661429: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-09 23:52:10.665206: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-09 23:52:15.325565: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280f63f0-8421-4427-b67d-dec2c73fcefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.14.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62882d0e-2c2e-44fa-a739-df7616a8321c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                60        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91 (364.00 Byte)\n",
      "Trainable params: 91 (364.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_model = keras.models.Sequential()\n",
    "mlp_model.add(keras.layers.Dense(5, activation='relu', input_shape=(3,))) \n",
    "mlp_model.add(keras.layers.Dense(10, activation='sigmoid'))\n",
    "mlp_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "mlp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72eeeb23-b599-4487-91e6-ed9fa75b0096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                60        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91 (364.00 Byte)\n",
      "Trainable params: 91 (364.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# how many layer and neurons are hyper parameters\n",
    "\n",
    "mlp_model = keras.models.Sequential(\n",
    "    [\n",
    "        # input shape is 3 features + bias; feeding into a 5 neuron Dense layer; thus 20 params\n",
    "        keras.layers.Dense(5, activation='relu', input_shape=(3,)),\n",
    "        # then 5 neurons + bias into 10 neurons Dense layer; thus 60 params\n",
    "        keras.layers.Dense(10, activation='sigmoid'),\n",
    "        # then 10 neurons + bias into one output layer; thus 11 params\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 'mse' for regression\n",
    "# 'binary_crossentropy' for classification\n",
    "mlp_model.compile(loss='mse',\n",
    "                  optimizer='adam')\n",
    "\n",
    "mlp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eda75c60-39e9-4dc3-a263-92104396631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp_model.fit(X, y, epochs=300) # epochs = iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe22590-3e7c-449e-9af5-ea1a8308d9d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ad32f9-02ea-45c1-9316-9dbdd90379f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### SET UP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc0b098-81dc-4985-a973-4fae3d1159eb",
   "metadata": {},
   "source": [
    "Consider the data “Advertising.csv”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02223fbf-a9ad-4d58-8f0d-f9f620ec2e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a8e56e-cc23-4488-9e44-577bf02de2a3",
   "metadata": {},
   "source": [
    "1. Scale the features using MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4701f70-412d-4d4e-a468-0650d5c551bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Advertising.csv\")\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "X = df[['TV', 'radio', 'newspaper']]\n",
    "y = df[['sales']]\n",
    "\n",
    "scaler = MinMaxScaler().fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5ee2da-d7a5-4ff5-b892-f7159d199241",
   "metadata": {},
   "source": [
    "2. Split the scaled data into 80% training data and 20% test data with train test split. Set random state\n",
    "= 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee3de1cc-cd03-4808-b9ad-fb4b2b22e6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7832dc45-4f9c-4ef9-acc9-17ccac44ca36",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Exercise 1: \n",
    "\n",
    "Perform the linear regression from scikit-learn to study the expense of TV, newspaper, and\n",
    "radio advertising on the sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ccb12e9-d1db-4dd1-98de-e2bc320f0d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a239f9d2-0b6a-466d-8914-21e4e4875a72",
   "metadata": {},
   "source": [
    "1. Use the ordinary linear regression to train the model. What are the learned model parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "454d1644-58c0-40d7-bca5-ebae8f857e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained model parameters are:\n",
      "Model Coef: [[13.22651832  9.38407469  0.3139387 ]]\n",
      "Model intercept: [3.01120633]\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "a = model.coef_\n",
    "b = model.intercept_\n",
    "\n",
    "print(\"trained model parameters are:\")\n",
    "print(f\"Model Coef: {a}\")\n",
    "print(f\"Model intercept: {b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56c5fb3-98f0-4e4f-a82b-cd0b4afbd151",
   "metadata": {},
   "source": [
    "2. Compare the R2 scores from training and test data, and discuss your observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72cbf146-d667-42d1-b765-4e76cabdadf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training data (R^2): 0.8957008271017818\n",
      "Accuracy for testing data (R^2): 0.899438024100912\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = model.score(x_train, y_train, sample_weight=None)\n",
    "test_accuracy = model.score(x_test, y_test, sample_weight=None)\n",
    "\n",
    "print(f'Accuracy for training data (R^2): {train_accuracy}')\n",
    "print(f'Accuracy for testing data (R^2): {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b949be0-8eac-4a88-a7c9-45d5dac496b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Exercise 2: \n",
    "\n",
    "Repeat the tasks in Exercise 1 with the KNN from scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36481b40-b393-45d7-97a7-ce207f858fcc",
   "metadata": {},
   "source": [
    "1. Choose the nearest neighbors K = 1. Use the KNeighborsRegressor to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d3011a4-6dad-4bd8-af51-453e6f3dd4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "563b0fb1-b0bf-4339-92a6-50b2dc8e0f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsRegressor(n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor(n_neighbors=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 1\n",
    "neigh = KNeighborsRegressor(n_neighbors=k)\n",
    "neigh.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f0820f-0704-4434-b625-11093871e074",
   "metadata": {},
   "source": [
    "2. Compare the R2 scores from training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d81f92b8-e2c5-45bd-aea5-c37c4df3bad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training data (R^2):  1.0\n",
      "Accuracy for test data (R^2):  0.9025380308603167 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ypred_train        = neigh.predict(x_train)\n",
    "accuracy_train     = r2_score(y_train, ypred_train)\n",
    "print('Accuracy for training data (R^2): ', accuracy_train)\n",
    "\n",
    "ypred_test         = neigh.predict(x_test)\n",
    "accuracy_test      = r2_score(y_test,ypred_test)\n",
    "print('Accuracy for test data (R^2): ', accuracy_test, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0364dd4b-90f8-4543-b39c-2c4ce51dfd31",
   "metadata": {},
   "source": [
    "3. Repeat your studies for K = 2, 3, . . . , 10. What are your observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0598f65-9497-43fc-ae0b-9967f7a389c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 2\n",
      "Accuracy for training data (R^2):  0.9812430719552749\n",
      "Accuracy for test data (R^2):  0.9324894681867459\n",
      "\n",
      "k: 3\n",
      "Accuracy for training data (R^2):  0.9718620977717801\n",
      "Accuracy for test data (R^2):  0.9364836092038614\n",
      "\n",
      "k: 4\n",
      "Accuracy for training data (R^2):  0.9671987204202612\n",
      "Accuracy for test data (R^2):  0.9299073794472469\n",
      "\n",
      "k: 5\n",
      "Accuracy for training data (R^2):  0.9665527977251915\n",
      "Accuracy for test data (R^2):  0.9337192077502264\n",
      "\n",
      "k: 6\n",
      "Accuracy for training data (R^2):  0.9632464215142899\n",
      "Accuracy for test data (R^2):  0.9498780845328242\n",
      "\n",
      "k: 7\n",
      "Accuracy for training data (R^2):  0.9597421955914276\n",
      "Accuracy for test data (R^2):  0.9503836147120786\n",
      "\n",
      "k: 8\n",
      "Accuracy for training data (R^2):  0.9570375379536363\n",
      "Accuracy for test data (R^2):  0.9461417178612622\n",
      "\n",
      "k: 9\n",
      "Accuracy for training data (R^2):  0.9512721124742588\n",
      "Accuracy for test data (R^2):  0.9420403901172719\n",
      "\n",
      "k: 10\n",
      "Accuracy for training data (R^2):  0.9477586389705528\n",
      "Accuracy for test data (R^2):  0.9382764359650904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(2,10+1):\n",
    "    neigh = KNeighborsRegressor(n_neighbors=k)\n",
    "    neigh.fit(x_train, y_train)\n",
    "    \n",
    "    print(f\"k: {k}\")\n",
    "    \n",
    "    ypred_train        = neigh.predict(x_train)\n",
    "    accuracy_train     = r2_score(y_train, ypred_train)\n",
    "    print('Accuracy for training data (R^2): ', accuracy_train)\n",
    "\n",
    "    ypred_test         = neigh.predict(x_test)\n",
    "    accuracy_test      = r2_score(y_test,ypred_test)\n",
    "    print('Accuracy for test data (R^2): ', accuracy_test)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec1e5eb-1649-4823-8f92-86fcefb7845b",
   "metadata": {},
   "source": [
    "Best balance between training and testing accuracy seems to be K = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8047021-ad92-4dae-8c38-e2090dc721e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Exercise 3: \n",
    "\n",
    "Repeat the tasks in Exercise 1 with neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a6d6db-b25e-4937-85ba-7f4db4384bab",
   "metadata": {},
   "source": [
    "1. Use Keras to build a neural network with input layer = output layer (i.e., only one layer), no\n",
    "activation function, choose mean square errors as the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbf57e93-2dee-4c90-be6a-d7781e7cb14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4 (16.00 Byte)\n",
      "Trainable params: 4 (16.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# how many layer and neurons are hyper parameters\n",
    "\n",
    "p_model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(1, input_shape=(3,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 'mse' for regression\n",
    "# 'binary_crossentropy' for classification\n",
    "p_model.compile(loss='mse',\n",
    "                  optimizer='adam')\n",
    "\n",
    "p_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f5495b-b302-403e-9ce2-a1750f231efb",
   "metadata": {},
   "source": [
    "2. Use the training data to train the neural network with epochs = 5000. What are the weights and\n",
    "bias parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74e6f777-22d7-49b6-8cdc-2df480512778",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "EPOCHS=5_000\n",
    "p_model.fit(x_train, y_train, epochs=EPOCHS) # epochs = iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6796bf5-74d8-441e-b364-78f39adc85b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for dense_6: [[13.143192  ]\n",
      " [ 9.259298  ]\n",
      " [ 0.44624153]]\n",
      "Biases for dense_6: [3.0824132]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the weights and biases of each layer\n",
    "for layer in p_model.layers:\n",
    "    weights, biases = layer.get_weights()\n",
    "    print(f\"Weights for {layer.name}: {weights}\")\n",
    "    print(f\"Biases for {layer.name}: {biases}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89135f4c-db85-450a-b5e3-e646ffbc61df",
   "metadata": {},
   "source": [
    "3. compare the R2 scores from training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "689a3833-44b0-46d1-9be9-bba28e47bffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step\n",
      "Accuracy for training data (R^2):  0.8956264807756238 \n",
      "\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Accuracy for test data (R^2):  0.8984392113011369 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ypred_train        = p_model.predict(x_train)\n",
    "accuracy_train     = r2_score(y_train, ypred_train)\n",
    "print('Accuracy for training data (R^2): ', accuracy_train, '\\n')\n",
    "\n",
    "ypred_test         = p_model.predict(x_test)\n",
    "accuracy_test      = r2_score(y_test,ypred_test)\n",
    "print('Accuracy for test data (R^2): ', accuracy_test, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec536427-ed0a-402f-be49-7302db0ddca2",
   "metadata": {},
   "source": [
    "4. Compare the models from Exercise 1 and 3. What are your observations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9505d1e6-256a-4cd1-8c14-078489ca5a2e",
   "metadata": {},
   "source": [
    "The model parameters are the pretty much the same. Given more epochs, they would probably be equivalent. They both have effectively the same accuracy as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a62c883-9836-4832-bb5d-88ac273255fa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Exercise 4: \n",
    "\n",
    "Repeat the tasks in Exercise 1 with neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b8545a7-9b4d-4b1b-9f96-fdece9625668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af50f1e-fdb4-4fe3-9405-fcd88f9adb5d",
   "metadata": {},
   "source": [
    "1. Use Keras to build a neural network with input layer (128 neurons), two hidden layers (64 and\n",
    "32 neurons), and output layer (1 neuron). Set the activation function in input and hidden layers\n",
    "as ‘ReLu’. Choose mean square errors as the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f9a8a15-c54d-4e4c-96f8-09019d51dc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 128)               512       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10881 (42.50 KB)\n",
      "Trainable params: 10881 (42.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# how many layer and neurons are hyper parameters\n",
    "\n",
    "n_model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(128, activation='relu', input_shape=(3,)),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.Dense(1)\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "# 'mse' for regression\n",
    "# 'binary_crossentropy' for classification\n",
    "n_model.compile(loss='mse',\n",
    "                  optimizer='adam')\n",
    "\n",
    "n_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30457a7-4883-403c-b1b4-2308bb73a430",
   "metadata": {},
   "source": [
    "2. Use the training data to train the neural network with epochs = 5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6da4058a-48c6-4ca2-9539-84d88b543641",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "EPOCHS=5_000\n",
    "n_model.fit(x_train, y_train, epochs=EPOCHS) # epochs = iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d05d562e-6759-4011-9ec0-2d67cef73bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a lot of weights and biases so I will only print their shape: \n",
      "\n",
      "Weights for dense_7: (3, 128)\n",
      "Biases for dense_7: (128,)\n",
      "\n",
      "Weights for dense_8: (128, 64)\n",
      "Biases for dense_8: (64,)\n",
      "\n",
      "Weights for dense_9: (64, 32)\n",
      "Biases for dense_9: (32,)\n",
      "\n",
      "Weights for dense_10: (32, 1)\n",
      "Biases for dense_10: (1,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the weights and biases of each layer\n",
    "print(f\"There is a lot of weights and biases so I will only print their shape: \\n\")\n",
    "for layer in n_model.layers:\n",
    "    weights, biases = layer.get_weights()\n",
    "    print(f\"Weights for {layer.name}: {np.shape(weights)}\")\n",
    "    print(f\"Biases for {layer.name}: {np.shape(biases)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e2a1fd-3f7d-4be0-9986-d6940cfa46a8",
   "metadata": {},
   "source": [
    "3. Compare the R2 scores from training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87a56065-9aec-4091-aba8-8377f293135a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n",
      "Accuracy for training data (R^2):  0.9985499057259037 \n",
      "\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Accuracy for test data (R^2):  0.9912788515050607 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ypred_train        = n_model.predict(x_train)\n",
    "accuracy_train     = r2_score(y_train, ypred_train)\n",
    "print('Accuracy for training data (R^2): ', accuracy_train, '\\n')\n",
    "\n",
    "ypred_test         = n_model.predict(x_test)\n",
    "accuracy_test      = r2_score(y_test,ypred_test)\n",
    "print('Accuracy for test data (R^2): ', accuracy_test, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4e705c-c392-44cc-a905-3c62ea55b31d",
   "metadata": {},
   "source": [
    "4. Compare the models from Exercise 3 and 4. What are your observations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d96c2a3-5743-4555-9fc0-fa551a382975",
   "metadata": {},
   "source": [
    "The model in ex4 performs much better than the one from ex3 base on accuracy of training and testing models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f2fada-a5ce-4ffb-bd1f-a9d500ee21ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2e4379-ead5-4003-a72c-bef838ecafec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0765eca-f511-4333-9648-4dc9fb05c677",
   "metadata": {},
   "source": [
    "Consider the data “diagnosis.csv”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f78de71-febe-4a46-961b-25b25fa877c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f800dfc-60a8-4313-ad28-bc346f80b481",
   "metadata": {},
   "source": [
    "1. Take the feature as “radius mean”, “texture mean”, “smoothness mean”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed75d90d-6822-48a5-a978-c19d04a79347",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./diagnosis.csv\")\n",
    "X = df[[\"radius_mean\", \"texture_mean\", \"smoothness_mean\"]]\n",
    "y = df[\"diagnosis\"]\n",
    "labelEncoder = LabelEncoder()\n",
    "y_encoded = labelEncoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19455e5-5160-4766-85f3-9d5c89bbbe29",
   "metadata": {},
   "source": [
    "2. Scale the features using MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00f3a451-ae3d-4a68-9090-8d688e88a8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler().fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7eeec7-cbea-4745-bc41-10eefe8a2e3b",
   "metadata": {},
   "source": [
    "3. Split the scaled data into 80% training data and 20% test data with train test split. Set random state\n",
    "= 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ded41db7-2900-44ca-ae08-8bcfdb647eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec79919-1c50-4b30-98ed-54d33cfef72a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exercise 5: \n",
    "\n",
    "Perform the logistic regression from scikit-learn for the selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f48624d7-47c6-4e14-bd25-4d975b9300a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055780a0-18fd-4ff9-a189-4d700cf8d24b",
   "metadata": {},
   "source": [
    "1. Use the logistic regression to train the model. What are the learned model parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c1e60cb-7ce1-4776-b1bd-cdf57f0debc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained model parameters are:\n",
      "Model Coef: [[7.34067597 3.30984355 3.77468867]]\n",
      "Model intercept: [-5.65721378]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "a = model.coef_\n",
    "b = model.intercept_\n",
    "\n",
    "print(\"trained model parameters are:\")\n",
    "print(f\"Model Coef: {a}\")\n",
    "print(f\"Model intercept: {b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd05f717-bd4e-41e9-b21f-edf1cda0f65e",
   "metadata": {},
   "source": [
    "2. Compare the accuracy from the training and test data, and discuss your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6e57257-5114-43cb-90a8-976b983f092b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training data (R^2):  0.9120879120879121 \n",
      "\n",
      "Confusion matrix for training data:\n",
      " [[281   5]\n",
      " [ 35 134]] \n",
      "\n",
      "Accuracy for test data (R^2):  0.9385964912280702 \n",
      "\n",
      "Confusion matrix for test data:\n",
      " [[71  0]\n",
      " [ 7 36]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ypred_train        = model.predict(x_train)\n",
    "accuracy_train     = accuracy_score(y_train, ypred_train)\n",
    "conf_matrix_train  = confusion_matrix(y_train, ypred_train)\n",
    "print('Accuracy for training data (R^2): ', accuracy_train, '\\n')\n",
    "print('Confusion matrix for training data:\\n', conf_matrix_train, '\\n')\n",
    "\n",
    "ypred_test         = model.predict(x_test)\n",
    "accuracy_test      = accuracy_score(y_test,ypred_test)\n",
    "conf_matrix_test   = confusion_matrix(y_test, ypred_test)\n",
    "print('Accuracy for test data (R^2): ', accuracy_test, '\\n')\n",
    "print('Confusion matrix for test data:\\n', conf_matrix_test, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ce6107-0576-44e5-b0bb-c053f1625d09",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Exercise 6: \n",
    "    \n",
    "Repeat the tasks in Exercise 5 with the KNN from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ec9c294-48de-4e7b-821e-efe5b9fd1a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a63dc65-b85f-43e9-ad2c-a0b708aa93e8",
   "metadata": {},
   "source": [
    "1. Choose the nearest neighbors K = 1. Use the KNeighborsClassifier to train the model\n",
    "2. Compare the accuracy from training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c03d0a9c-083e-4c38-8454-503d6fcedeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training data (R^2):  1.0\n",
      "Confusion matrix for training data:\n",
      " [[286   0]\n",
      " [  0 169]] \n",
      "\n",
      "Accuracy for test data (R^2):  0.9298245614035088 \n",
      "\n",
      "Confusion matrix for test data:\n",
      " [[65  6]\n",
      " [ 2 41]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "neigh.fit(x_train, y_train)\n",
    "\n",
    "ypred_train        = neigh.predict(x_train)\n",
    "accuracy_train     = accuracy_score(y_train, ypred_train)\n",
    "conf_matrix_train  = confusion_matrix(y_train, ypred_train)\n",
    "print('Accuracy for training data (R^2): ', accuracy_train)\n",
    "print('Confusion matrix for training data:\\n', conf_matrix_train, '\\n')\n",
    "\n",
    "ypred_test         = neigh.predict(x_test)\n",
    "accuracy_test      = accuracy_score(y_test,ypred_test)\n",
    "conf_matrix_test   = confusion_matrix(y_test, ypred_test)\n",
    "print('Accuracy for test data (R^2): ', accuracy_test, '\\n')\n",
    "print('Confusion matrix for test data:\\n', conf_matrix_test, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3e47c9-afa4-489b-a847-4607371c2219",
   "metadata": {},
   "source": [
    "3. Repeat your studies for K = 3, 5, . . . , 9. What are your observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76beff11-b60b-45a3-ae29-452d3bdc7a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 3\n",
      "Accuracy for training data (R^2):  0.9384615384615385\n",
      "Confusion matrix for training data:\n",
      " [[276  10]\n",
      " [ 18 151]] \n",
      "\n",
      "Accuracy for test data (R^2):  0.9035087719298246 \n",
      "\n",
      "Confusion matrix for test data:\n",
      " [[66  5]\n",
      " [ 6 37]] \n",
      "\n",
      "\n",
      "k: 5\n",
      "Accuracy for training data (R^2):  0.9274725274725275\n",
      "Confusion matrix for training data:\n",
      " [[275  11]\n",
      " [ 22 147]] \n",
      "\n",
      "Accuracy for test data (R^2):  0.9298245614035088 \n",
      "\n",
      "Confusion matrix for test data:\n",
      " [[68  3]\n",
      " [ 5 38]] \n",
      "\n",
      "\n",
      "k: 7\n",
      "Accuracy for training data (R^2):  0.9274725274725275\n",
      "Confusion matrix for training data:\n",
      " [[275  11]\n",
      " [ 22 147]] \n",
      "\n",
      "Accuracy for test data (R^2):  0.9473684210526315 \n",
      "\n",
      "Confusion matrix for test data:\n",
      " [[69  2]\n",
      " [ 4 39]] \n",
      "\n",
      "\n",
      "k: 9\n",
      "Accuracy for training data (R^2):  0.9296703296703297\n",
      "Confusion matrix for training data:\n",
      " [[274  12]\n",
      " [ 20 149]] \n",
      "\n",
      "Accuracy for test data (R^2):  0.956140350877193 \n",
      "\n",
      "Confusion matrix for test data:\n",
      " [[69  2]\n",
      " [ 3 40]] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(3,10+1,2):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "    neigh.fit(x_train, y_train)\n",
    "    \n",
    "    print(f\"k: {k}\")\n",
    "    \n",
    "    ypred_train        = neigh.predict(x_train)\n",
    "    accuracy_train     = accuracy_score(y_train, ypred_train)\n",
    "    conf_matrix_train  = confusion_matrix(y_train, ypred_train)\n",
    "    print('Accuracy for training data (R^2): ', accuracy_train)\n",
    "    print('Confusion matrix for training data:\\n', conf_matrix_train, '\\n')\n",
    "\n",
    "    ypred_test         = neigh.predict(x_test)\n",
    "    accuracy_test      = accuracy_score(y_test,ypred_test)\n",
    "    conf_matrix_test   = confusion_matrix(y_test, ypred_test)\n",
    "    print('Accuracy for test data (R^2): ', accuracy_test, '\\n')\n",
    "    print('Confusion matrix for test data:\\n', conf_matrix_test, '\\n')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881dcb41-4673-433b-9a21-4d1dceaafcb5",
   "metadata": {},
   "source": [
    "k=9 seems to yield the best testing data accuracy. K is odd numbers because we need a tie breaker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe4c01f-e6d2-4e72-8f4b-0f873dc6f65f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exercise 7:\n",
    "Repeat the tasks in Exercise 5 with neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d15838-2f48-42d6-80d3-7b6ef93e0d07",
   "metadata": {},
   "source": [
    "1. Use Keras to build a neural network with input layer = output layer (i.e., only one layer), sigmoid\n",
    "activation function, choose binary cross entropy as the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f44684e5-5eae-4a57-9ac0-d56f26811a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4 (16.00 Byte)\n",
      "Trainable params: 4 (16.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# how many layer and neurons are hyper parameters\n",
    "\n",
    "s_model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(1, activation='sigmoid', input_shape=(3,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 'mse' for regression\n",
    "# 'binary_crossentropy' for classification\n",
    "s_model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam')\n",
    "\n",
    "s_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e76bf1-370d-4b7f-9f5c-76934de15c8e",
   "metadata": {},
   "source": [
    "2. Use the training data to train the neural network with epochs = 5000. What are the weights and\n",
    "bias parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07969d28-e030-4835-9af0-a97ad4245169",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "EPOCHS=5_000\n",
    "s_model.fit(x_train, y_train, epochs=EPOCHS) # epochs = iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f21b45d-7b1f-4f42-94db-ebbd61ffbdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for dense_11: [[18.00087  ]\n",
      " [ 6.7832255]\n",
      " [ 9.31838  ]]\n",
      "Biases for dense_11: [-12.649803]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the weights and biases of each layer\n",
    "for layer in s_model.layers:\n",
    "    weights, biases = layer.get_weights()\n",
    "    print(f\"Weights for {layer.name}: {weights}\")\n",
    "    print(f\"Biases for {layer.name}: {biases}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a49ed9-988a-4b1d-94e1-a52618a40381",
   "metadata": {},
   "source": [
    "3. Compare the accuracy from training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8fa1fee-1483-4d4f-a70a-c6f105bc0169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4384201620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Accuracy for training data (R^2);  0.5 threshold: 0.9230769230769231 \n",
      "\n",
      "Confusion matrix for training data:\n",
      " [[273  13]\n",
      " [ 22 147]] \n",
      "\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Accuracy for test data (R^2); 0.5 threshold: 0.9385964912280702 \n",
      "\n",
      "Confusion matrix for test data:\n",
      " [[68  3]\n",
      " [ 4 39]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "ypred_train        = s_model.predict(x_train)\n",
    "ypred_train         = (ypred_train >= threshold).astype(int)\n",
    "accuracy_train     = accuracy_score(y_train, ypred_train)\n",
    "conf_matrix_train  = confusion_matrix(y_train, ypred_train)\n",
    "print(f'Accuracy for training data (R^2);  {threshold} threshold: {accuracy_train} \\n')\n",
    "print('Confusion matrix for training data:\\n', conf_matrix_train, '\\n')\n",
    "\n",
    "\n",
    "ypred_test         = s_model.predict(x_test)\n",
    "ypred_test         = (ypred_test >= threshold).astype(int)\n",
    "accuracy_test      = accuracy_score(y_test,ypred_test)\n",
    "conf_matrix_test   = confusion_matrix(y_test, ypred_test)\n",
    "print(f'Accuracy for test data (R^2); {threshold} threshold: {accuracy_test} \\n')\n",
    "print('Confusion matrix for test data:\\n', conf_matrix_test, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e468a484-1b2a-4023-a9ed-c3bdd3f06fe1",
   "metadata": {},
   "source": [
    "4. Compare the models parameters from Exercise 7 and 5. Explain your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116fcdc4-c455-44a1-9b3d-7f8183cb802b",
   "metadata": {},
   "source": [
    "The weights and bias look very different but the accuracy for both training and testing is effectively the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289d52fa-e8dc-4418-a0a9-636b1ccabb18",
   "metadata": {},
   "source": [
    "5. Repeat Tasks 2–4 by training the neural network with epochs = 12000. Compare your results\n",
    "with those observed with epochs = 5000. What are your observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe8feb71-f2b6-4675-a4bf-ae2133647461",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "EPOCHS=12_000\n",
    "s_model.fit(x_train, y_train, epochs=EPOCHS) # epochs = iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d03b5a21-1599-487f-8b1c-2e227a41297e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for dense_11: [[24.523485]\n",
      " [ 9.577901]\n",
      " [13.666807]]\n",
      "Biases for dense_11: [-17.632284]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the weights and biases of each layer\n",
    "for layer in s_model.layers:\n",
    "    weights, biases = layer.get_weights()\n",
    "    print(f\"Weights for {layer.name}: {weights}\")\n",
    "    print(f\"Biases for {layer.name}: {biases}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b309573-7919-48ad-817c-aaceaf1e6e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 885us/step\n",
      "Accuracy for training data (R^2);  0.5 threshold: 0.9274725274725275 \n",
      "\n",
      "Confusion matrix for training data:\n",
      " [[273  13]\n",
      " [ 20 149]] \n",
      "\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Accuracy for test data (R^2); 0.5 threshold: 0.9473684210526315 \n",
      "\n",
      "Confusion matrix for test data:\n",
      " [[68  3]\n",
      " [ 3 40]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "ypred_train        = s_model.predict(x_train)\n",
    "ypred_train         = (ypred_train >= threshold).astype(int)\n",
    "accuracy_train     = accuracy_score(y_train, ypred_train)\n",
    "conf_matrix_train  = confusion_matrix(y_train, ypred_train)\n",
    "print(f'Accuracy for training data (R^2);  {threshold} threshold: {accuracy_train} \\n')\n",
    "print('Confusion matrix for training data:\\n', conf_matrix_train, '\\n')\n",
    "\n",
    "\n",
    "ypred_test         = s_model.predict(x_test)\n",
    "ypred_test         = (ypred_test >= threshold).astype(int)\n",
    "accuracy_test      = accuracy_score(y_test,ypred_test)\n",
    "conf_matrix_test   = confusion_matrix(y_test, ypred_test)\n",
    "print(f'Accuracy for test data (R^2); {threshold} threshold: {accuracy_test} \\n')\n",
    "print('Confusion matrix for test data:\\n', conf_matrix_test, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257ca53f-4790-4043-b5ed-707c314bb821",
   "metadata": {},
   "source": [
    "Small addvantage in accuracy and very different weights and bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfea899-bf96-4426-90e5-287d633807e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exercise 8: \n",
    "Repeat the tasks in Exercise 5 with neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c441cb80-88e9-41b6-ac65-58c5abefa131",
   "metadata": {},
   "source": [
    "1. Use Keras to build a neural network with input layer (128 neurons), two hidden layers (64 and\n",
    "32 neurons), and output layer (1 neuron). Set the activation function in input and hidden layers\n",
    "as ‘ReLu’. Choose binary cross entropy as the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "103b39a1-745e-4ba7-b563-ebe4adb09a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 128)               512       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10881 (42.50 KB)\n",
      "Trainable params: 10881 (42.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# how many layer and neurons are hyper parameters\n",
    "\n",
    "ms_model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(128, activation='relu', input_shape=(3,)),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 'mse' for regression\n",
    "# 'binary_crossentropy' for classification\n",
    "ms_model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam')\n",
    "\n",
    "ms_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f13f7-7698-478a-9eb4-45310aefb8fc",
   "metadata": {},
   "source": [
    "2. Use the training data to train the neural network with epochs = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "732f8cc2-e827-443e-8b77-816edc381f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "EPOCHS=5_000\n",
    "ms_model.fit(x_train, y_train, epochs=EPOCHS) # epochs = iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c3e88a31-1c94-4fdf-a34d-10af63c5bd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for dense_12: (3, 128)\n",
      "Biases for dense_12: (128,)\n",
      "\n",
      "Weights for dense_13: (128, 64)\n",
      "Biases for dense_13: (64,)\n",
      "\n",
      "Weights for dense_14: (64, 32)\n",
      "Biases for dense_14: (32,)\n",
      "\n",
      "Weights for dense_15: (32, 1)\n",
      "Biases for dense_15: (1,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the weights and biases of each layer\n",
    "for layer in ms_model.layers:\n",
    "    weights, biases = layer.get_weights()\n",
    "    print(f\"Weights for {layer.name}: {np.shape(weights)}\")\n",
    "    print(f\"Biases for {layer.name}: {np.shape(biases)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a15ccf-4042-4913-a72a-d2b7b29b3ee1",
   "metadata": {},
   "source": [
    "3. Compare the accuracy from training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c53e8fe-99a3-498e-b88d-6b9fbca52b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 1ms/step\n",
      "Accuracy for training data (R^2);  0.5 threshold: 1.0 \n",
      "\n",
      "Confusion matrix for training data:\n",
      " [[286   0]\n",
      " [  0 169]] \n",
      "\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Accuracy for test data (R^2); 0.5 threshold: 0.9385964912280702 \n",
      "\n",
      "Confusion matrix for test data:\n",
      " [[68  3]\n",
      " [ 4 39]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "ypred_train        = ms_model.predict(x_train)\n",
    "ypred_train        = (ypred_train >= threshold).astype(int)\n",
    "accuracy_train     = accuracy_score(y_train, ypred_train)\n",
    "conf_matrix_train  = confusion_matrix(y_train, ypred_train)\n",
    "print(f'Accuracy for training data (R^2);  {threshold} threshold: {accuracy_train} \\n')\n",
    "print('Confusion matrix for training data:\\n', conf_matrix_train, '\\n')\n",
    "\n",
    "ypred_test         = ms_model.predict(x_test)\n",
    "ypred_test     = (ypred_test >= threshold).astype(int)\n",
    "accuracy_test      = accuracy_score(y_test,ypred_test)\n",
    "conf_matrix_test   = confusion_matrix(y_test, ypred_test)\n",
    "print(f'Accuracy for test data (R^2); {threshold} threshold: {accuracy_test} \\n')\n",
    "print('Confusion matrix for test data:\\n', conf_matrix_test, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23659df2-8447-4495-8dce-7374653a8212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8c497c4-ad68-4be7-b4b8-3a8f21451ed1",
   "metadata": {},
   "source": [
    "4. Compare the models from Exercise 7 and 8. What are your observations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4df4f8e-7801-4b02-bbf0-cfccb301a5cf",
   "metadata": {},
   "source": [
    "This one seems to be overfitted as the training data achieved perfect accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82716cd7-c647-4cb6-8250-25131549b87e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
